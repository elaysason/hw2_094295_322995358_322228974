{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1op-CbyLuN4",
        "outputId": "58260494-7b21-4328-c0f5-a0d50e5b388f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/107.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m102.4/107.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.6/107.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "torch.manual_seed(7)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import requests\n",
        "import os\n",
        "import torch\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "from torch_geometric.nn import GATConv\n",
        "from torch_geometric.data import Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imGrKO5YH11-",
        "outputId": "1309446b-c8a5-4f78-a8a6-bc0586e10519"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Deffining the dataset\n",
        "\n",
        "class HW3Dataset(Dataset):\n",
        "    url = 'https://technionmail-my.sharepoint.com/:u:/g/personal/ploznik_campus_technion_ac_il/EUHUDSoVnitIrEA6ALsAK1QBpphP5jX3OmGyZAgnbUFo0A?download=1'\n",
        "\n",
        "    def __init__(self, root, transform=None, pre_transform=None):\n",
        "        super(HW3Dataset, self).__init__(root, transform, pre_transform)\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return ['data.pt']\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return ['data.pt']\n",
        "\n",
        "    def download(self):\n",
        "        file_url = self.url.replace(' ', '%20')\n",
        "        response = requests.get(file_url)\n",
        "\n",
        "        if response.status_code != 200:\n",
        "            raise Exception(f\"Failed to download the file, status code: {response.status_code}\")\n",
        "\n",
        "        with open(os.path.join(self.raw_dir, self.raw_file_names[0]), 'wb') as f:\n",
        "            f.write(response.content)\n",
        "\n",
        "    def process(self):\n",
        "        raw_path = os.path.join(self.raw_dir, self.raw_file_names[0])\n",
        "        data = torch.load(raw_path)\n",
        "        torch.save(data, self.processed_paths[0])\n",
        "\n",
        "    def len(self):\n",
        "        return 1\n",
        "\n",
        "    def get(self, idx):\n",
        "        return torch.load(self.processed_paths[0])\n",
        "\n",
        "\n",
        "dataset = HW3Dataset(root='data/hw3/')\n",
        "data = dataset[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, heads):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATConv(dataset.num_features,int(hidden_channels/2))\n",
        "        self.conv2 = GATConv(int(hidden_channels/2),hidden_channels)\n",
        "        self.conv3 = GATConv(hidden_channels,dataset.num_classes)\n",
        "        # adding batch norm layers to generalize the data\n",
        "        self.bn1 = torch.nn.BatchNorm1d(int(hidden_channels/2))\n",
        "        self.bn2 = torch.nn.BatchNorm1d(int(hidden_channels))\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.bn1(x)\n",
        "        x = F.tanh(x)\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        x = F.tanh(x)\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        return x\n",
        "\n",
        "model = GAT(hidden_channels=128, heads=128)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.004, weight_decay=5e-4)\n",
        "# splitting the test into val and test.\n",
        "val_mask, test_mask = train_test_split(data.val_mask, test_size=0.5, random_state=7)\n",
        "our_loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train(mask):\n",
        "      model.train()\n",
        "      optimizer.zero_grad()\n",
        "      out = model(data.x, data.edge_index)\n",
        "      # Calculation of the loss\n",
        "      loss = our_loss(out[mask], data.y[mask].view(-1))\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      return loss\n",
        "\n",
        "def test(mask):\n",
        "      model.eval()\n",
        "      out = model(data.x, data.edge_index)\n",
        "      # Prefomring a maximum to find the predicted category\n",
        "      pred = out.argmax(dim=1)\n",
        "      return accuracy_score(data.y[mask],pred[mask])"
      ],
      "metadata": {
        "id": "Kwgf0ptJUZeW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stop the training if didnt see significant learning for a while\n",
        "best_acc_val = 0.0\n",
        "best_model = None\n",
        "patience = 100\n",
        "counter = 0\n",
        "\n",
        "for epoch in range(1, 501):\n",
        "    loss = train(data.train_mask)\n",
        "    val_acc = test(val_mask)\n",
        "\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Validation: {val_acc:.4f}')\n",
        "    if val_acc > best_acc_val:\n",
        "        best_acc_val = val_acc\n",
        "        best_model = model\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter >= patience:\n",
        "            print(\"Stopped training. There was no improvement for {} epochs.\".format(patience))\n",
        "            break\n",
        "\n",
        "# Loading the best model over the training process\n",
        "with open('final_model.pkl', 'wb') as f:\n",
        "    pickle.dump(best_model, f)\n",
        "print(best_acc_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEQIXaL7TeqJ",
        "outputId": "4de56d30-3337-4041-da6f-53f9ccb0af84"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Loss: 4.0165, Validation: 0.0680\n",
            "Epoch: 002, Loss: 3.6903, Validation: 0.1775\n",
            "Epoch: 003, Loss: 3.3923, Validation: 0.2485\n",
            "Epoch: 004, Loss: 3.1388, Validation: 0.2868\n",
            "Epoch: 005, Loss: 2.9157, Validation: 0.3080\n",
            "Epoch: 006, Loss: 2.7450, Validation: 0.3289\n",
            "Epoch: 007, Loss: 2.6175, Validation: 0.3500\n",
            "Epoch: 008, Loss: 2.5136, Validation: 0.3717\n",
            "Epoch: 009, Loss: 2.4237, Validation: 0.3939\n",
            "Epoch: 010, Loss: 2.3475, Validation: 0.4177\n",
            "Epoch: 011, Loss: 2.2787, Validation: 0.4396\n",
            "Epoch: 012, Loss: 2.2262, Validation: 0.4531\n",
            "Epoch: 013, Loss: 2.1810, Validation: 0.4622\n",
            "Epoch: 014, Loss: 2.1441, Validation: 0.4687\n",
            "Epoch: 015, Loss: 2.1067, Validation: 0.4749\n",
            "Epoch: 016, Loss: 2.0776, Validation: 0.4821\n",
            "Epoch: 017, Loss: 2.0530, Validation: 0.4873\n",
            "Epoch: 018, Loss: 2.0200, Validation: 0.4913\n",
            "Epoch: 019, Loss: 2.0022, Validation: 0.4978\n",
            "Epoch: 020, Loss: 1.9881, Validation: 0.5044\n",
            "Epoch: 021, Loss: 1.9577, Validation: 0.5089\n",
            "Epoch: 022, Loss: 1.9454, Validation: 0.5095\n",
            "Epoch: 023, Loss: 1.9299, Validation: 0.5129\n",
            "Epoch: 024, Loss: 1.9108, Validation: 0.5126\n",
            "Epoch: 025, Loss: 1.9029, Validation: 0.5126\n",
            "Epoch: 026, Loss: 1.8867, Validation: 0.5139\n",
            "Epoch: 027, Loss: 1.8713, Validation: 0.5175\n",
            "Epoch: 028, Loss: 1.8652, Validation: 0.5165\n",
            "Epoch: 029, Loss: 1.8538, Validation: 0.5175\n",
            "Epoch: 030, Loss: 1.8455, Validation: 0.5177\n",
            "Epoch: 031, Loss: 1.8332, Validation: 0.5175\n",
            "Epoch: 032, Loss: 1.8217, Validation: 0.5193\n",
            "Epoch: 033, Loss: 1.8175, Validation: 0.5206\n",
            "Epoch: 034, Loss: 1.8049, Validation: 0.5227\n",
            "Epoch: 035, Loss: 1.7965, Validation: 0.5233\n",
            "Epoch: 036, Loss: 1.7987, Validation: 0.5255\n",
            "Epoch: 037, Loss: 1.7952, Validation: 0.5263\n",
            "Epoch: 038, Loss: 1.7827, Validation: 0.5270\n",
            "Epoch: 039, Loss: 1.7764, Validation: 0.5287\n",
            "Epoch: 040, Loss: 1.7695, Validation: 0.5313\n",
            "Epoch: 041, Loss: 1.7647, Validation: 0.5323\n",
            "Epoch: 042, Loss: 1.7572, Validation: 0.5327\n",
            "Epoch: 043, Loss: 1.7502, Validation: 0.5333\n",
            "Epoch: 044, Loss: 1.7509, Validation: 0.5348\n",
            "Epoch: 045, Loss: 1.7453, Validation: 0.5365\n",
            "Epoch: 046, Loss: 1.7388, Validation: 0.5368\n",
            "Epoch: 047, Loss: 1.7395, Validation: 0.5381\n",
            "Epoch: 048, Loss: 1.7332, Validation: 0.5396\n",
            "Epoch: 049, Loss: 1.7315, Validation: 0.5405\n",
            "Epoch: 050, Loss: 1.7192, Validation: 0.5417\n",
            "Epoch: 051, Loss: 1.7136, Validation: 0.5423\n",
            "Epoch: 052, Loss: 1.7140, Validation: 0.5431\n",
            "Epoch: 053, Loss: 1.7131, Validation: 0.5434\n",
            "Epoch: 054, Loss: 1.7079, Validation: 0.5438\n",
            "Epoch: 055, Loss: 1.7014, Validation: 0.5443\n",
            "Epoch: 056, Loss: 1.6984, Validation: 0.5445\n",
            "Epoch: 057, Loss: 1.7011, Validation: 0.5461\n",
            "Epoch: 058, Loss: 1.6962, Validation: 0.5464\n",
            "Epoch: 059, Loss: 1.6916, Validation: 0.5463\n",
            "Epoch: 060, Loss: 1.6907, Validation: 0.5468\n",
            "Epoch: 061, Loss: 1.6852, Validation: 0.5476\n",
            "Epoch: 062, Loss: 1.6789, Validation: 0.5480\n",
            "Epoch: 063, Loss: 1.6770, Validation: 0.5484\n",
            "Epoch: 064, Loss: 1.6803, Validation: 0.5492\n",
            "Epoch: 065, Loss: 1.6792, Validation: 0.5494\n",
            "Epoch: 066, Loss: 1.6709, Validation: 0.5496\n",
            "Epoch: 067, Loss: 1.6711, Validation: 0.5493\n",
            "Epoch: 068, Loss: 1.6665, Validation: 0.5504\n",
            "Epoch: 069, Loss: 1.6656, Validation: 0.5508\n",
            "Epoch: 070, Loss: 1.6668, Validation: 0.5507\n",
            "Epoch: 071, Loss: 1.6593, Validation: 0.5510\n",
            "Epoch: 072, Loss: 1.6617, Validation: 0.5516\n",
            "Epoch: 073, Loss: 1.6514, Validation: 0.5521\n",
            "Epoch: 074, Loss: 1.6537, Validation: 0.5521\n",
            "Epoch: 075, Loss: 1.6458, Validation: 0.5522\n",
            "Epoch: 076, Loss: 1.6511, Validation: 0.5534\n",
            "Epoch: 077, Loss: 1.6474, Validation: 0.5535\n",
            "Epoch: 078, Loss: 1.6453, Validation: 0.5536\n",
            "Epoch: 079, Loss: 1.6461, Validation: 0.5539\n",
            "Epoch: 080, Loss: 1.6338, Validation: 0.5538\n",
            "Epoch: 081, Loss: 1.6453, Validation: 0.5540\n",
            "Epoch: 082, Loss: 1.6396, Validation: 0.5544\n",
            "Epoch: 083, Loss: 1.6358, Validation: 0.5551\n",
            "Epoch: 084, Loss: 1.6368, Validation: 0.5544\n",
            "Epoch: 085, Loss: 1.6330, Validation: 0.5546\n",
            "Epoch: 086, Loss: 1.6334, Validation: 0.5553\n",
            "Epoch: 087, Loss: 1.6267, Validation: 0.5566\n",
            "Epoch: 088, Loss: 1.6233, Validation: 0.5564\n",
            "Epoch: 089, Loss: 1.6225, Validation: 0.5570\n",
            "Epoch: 090, Loss: 1.6278, Validation: 0.5561\n",
            "Epoch: 091, Loss: 1.6234, Validation: 0.5564\n",
            "Epoch: 092, Loss: 1.6215, Validation: 0.5565\n",
            "Epoch: 093, Loss: 1.6201, Validation: 0.5574\n",
            "Epoch: 094, Loss: 1.6188, Validation: 0.5575\n",
            "Epoch: 095, Loss: 1.6222, Validation: 0.5571\n",
            "Epoch: 096, Loss: 1.6176, Validation: 0.5560\n",
            "Epoch: 097, Loss: 1.6148, Validation: 0.5567\n",
            "Epoch: 098, Loss: 1.6131, Validation: 0.5575\n",
            "Epoch: 099, Loss: 1.6163, Validation: 0.5572\n",
            "Epoch: 100, Loss: 1.6143, Validation: 0.5576\n",
            "Epoch: 101, Loss: 1.6124, Validation: 0.5581\n",
            "Epoch: 102, Loss: 1.6108, Validation: 0.5579\n",
            "Epoch: 103, Loss: 1.6062, Validation: 0.5579\n",
            "Epoch: 104, Loss: 1.6080, Validation: 0.5579\n",
            "Epoch: 105, Loss: 1.6017, Validation: 0.5568\n",
            "Epoch: 106, Loss: 1.6066, Validation: 0.5575\n",
            "Epoch: 107, Loss: 1.6015, Validation: 0.5581\n",
            "Epoch: 108, Loss: 1.6029, Validation: 0.5590\n",
            "Epoch: 109, Loss: 1.6040, Validation: 0.5599\n",
            "Epoch: 110, Loss: 1.5985, Validation: 0.5596\n",
            "Epoch: 111, Loss: 1.6012, Validation: 0.5593\n",
            "Epoch: 112, Loss: 1.6003, Validation: 0.5594\n",
            "Epoch: 113, Loss: 1.5990, Validation: 0.5581\n",
            "Epoch: 114, Loss: 1.6010, Validation: 0.5583\n",
            "Epoch: 115, Loss: 1.6002, Validation: 0.5595\n",
            "Epoch: 116, Loss: 1.5968, Validation: 0.5593\n",
            "Epoch: 117, Loss: 1.5957, Validation: 0.5595\n",
            "Epoch: 118, Loss: 1.5988, Validation: 0.5601\n",
            "Epoch: 119, Loss: 1.5961, Validation: 0.5607\n",
            "Epoch: 120, Loss: 1.5904, Validation: 0.5607\n",
            "Epoch: 121, Loss: 1.5909, Validation: 0.5620\n",
            "Epoch: 122, Loss: 1.5909, Validation: 0.5628\n",
            "Epoch: 123, Loss: 1.5900, Validation: 0.5622\n",
            "Epoch: 124, Loss: 1.5830, Validation: 0.5628\n",
            "Epoch: 125, Loss: 1.5900, Validation: 0.5617\n",
            "Epoch: 126, Loss: 1.5889, Validation: 0.5621\n",
            "Epoch: 127, Loss: 1.5867, Validation: 0.5620\n",
            "Epoch: 128, Loss: 1.5892, Validation: 0.5627\n",
            "Epoch: 129, Loss: 1.5838, Validation: 0.5626\n",
            "Epoch: 130, Loss: 1.5882, Validation: 0.5625\n",
            "Epoch: 131, Loss: 1.5844, Validation: 0.5621\n",
            "Epoch: 132, Loss: 1.5849, Validation: 0.5622\n",
            "Epoch: 133, Loss: 1.5805, Validation: 0.5618\n",
            "Epoch: 134, Loss: 1.5823, Validation: 0.5627\n",
            "Epoch: 135, Loss: 1.5810, Validation: 0.5629\n",
            "Epoch: 136, Loss: 1.5833, Validation: 0.5637\n",
            "Epoch: 137, Loss: 1.5850, Validation: 0.5645\n",
            "Epoch: 138, Loss: 1.5813, Validation: 0.5644\n",
            "Epoch: 139, Loss: 1.5769, Validation: 0.5644\n",
            "Epoch: 140, Loss: 1.5784, Validation: 0.5637\n",
            "Epoch: 141, Loss: 1.5809, Validation: 0.5640\n",
            "Epoch: 142, Loss: 1.5758, Validation: 0.5638\n",
            "Epoch: 143, Loss: 1.5805, Validation: 0.5640\n",
            "Epoch: 144, Loss: 1.5827, Validation: 0.5645\n",
            "Epoch: 145, Loss: 1.5770, Validation: 0.5651\n",
            "Epoch: 146, Loss: 1.5785, Validation: 0.5655\n",
            "Epoch: 147, Loss: 1.5741, Validation: 0.5653\n",
            "Epoch: 148, Loss: 1.5762, Validation: 0.5650\n",
            "Epoch: 149, Loss: 1.5779, Validation: 0.5657\n",
            "Epoch: 150, Loss: 1.5727, Validation: 0.5651\n",
            "Epoch: 151, Loss: 1.5719, Validation: 0.5644\n",
            "Epoch: 152, Loss: 1.5784, Validation: 0.5648\n",
            "Epoch: 153, Loss: 1.5754, Validation: 0.5646\n",
            "Epoch: 154, Loss: 1.5731, Validation: 0.5651\n",
            "Epoch: 155, Loss: 1.5784, Validation: 0.5662\n",
            "Epoch: 156, Loss: 1.5690, Validation: 0.5663\n",
            "Epoch: 157, Loss: 1.5750, Validation: 0.5664\n",
            "Epoch: 158, Loss: 1.5692, Validation: 0.5660\n",
            "Epoch: 159, Loss: 1.5661, Validation: 0.5649\n",
            "Epoch: 160, Loss: 1.5714, Validation: 0.5657\n",
            "Epoch: 161, Loss: 1.5725, Validation: 0.5655\n",
            "Epoch: 162, Loss: 1.5710, Validation: 0.5659\n",
            "Epoch: 163, Loss: 1.5691, Validation: 0.5655\n",
            "Epoch: 164, Loss: 1.5698, Validation: 0.5647\n",
            "Epoch: 165, Loss: 1.5647, Validation: 0.5660\n",
            "Epoch: 166, Loss: 1.5727, Validation: 0.5661\n",
            "Epoch: 167, Loss: 1.5667, Validation: 0.5663\n",
            "Epoch: 168, Loss: 1.5672, Validation: 0.5665\n",
            "Epoch: 169, Loss: 1.5675, Validation: 0.5662\n",
            "Epoch: 170, Loss: 1.5643, Validation: 0.5664\n",
            "Epoch: 171, Loss: 1.5616, Validation: 0.5661\n",
            "Epoch: 172, Loss: 1.5687, Validation: 0.5656\n",
            "Epoch: 173, Loss: 1.5652, Validation: 0.5653\n",
            "Epoch: 174, Loss: 1.5667, Validation: 0.5642\n",
            "Epoch: 175, Loss: 1.5651, Validation: 0.5660\n",
            "Epoch: 176, Loss: 1.5636, Validation: 0.5671\n",
            "Epoch: 177, Loss: 1.5633, Validation: 0.5664\n",
            "Epoch: 178, Loss: 1.5642, Validation: 0.5676\n",
            "Epoch: 179, Loss: 1.5637, Validation: 0.5672\n",
            "Epoch: 180, Loss: 1.5647, Validation: 0.5675\n",
            "Epoch: 181, Loss: 1.5677, Validation: 0.5670\n",
            "Epoch: 182, Loss: 1.5607, Validation: 0.5678\n",
            "Epoch: 183, Loss: 1.5619, Validation: 0.5680\n",
            "Epoch: 184, Loss: 1.5594, Validation: 0.5687\n",
            "Epoch: 185, Loss: 1.5636, Validation: 0.5680\n",
            "Epoch: 186, Loss: 1.5629, Validation: 0.5683\n",
            "Epoch: 187, Loss: 1.5636, Validation: 0.5675\n",
            "Epoch: 188, Loss: 1.5609, Validation: 0.5676\n",
            "Epoch: 189, Loss: 1.5609, Validation: 0.5669\n",
            "Epoch: 190, Loss: 1.5642, Validation: 0.5670\n",
            "Epoch: 191, Loss: 1.5632, Validation: 0.5681\n",
            "Epoch: 192, Loss: 1.5609, Validation: 0.5686\n",
            "Epoch: 193, Loss: 1.5568, Validation: 0.5686\n",
            "Epoch: 194, Loss: 1.5622, Validation: 0.5702\n",
            "Epoch: 195, Loss: 1.5548, Validation: 0.5679\n",
            "Epoch: 196, Loss: 1.5523, Validation: 0.5677\n",
            "Epoch: 197, Loss: 1.5618, Validation: 0.5675\n",
            "Epoch: 198, Loss: 1.5632, Validation: 0.5677\n",
            "Epoch: 199, Loss: 1.5579, Validation: 0.5690\n",
            "Epoch: 200, Loss: 1.5577, Validation: 0.5678\n",
            "Epoch: 201, Loss: 1.5614, Validation: 0.5679\n",
            "Epoch: 202, Loss: 1.5599, Validation: 0.5677\n",
            "Epoch: 203, Loss: 1.5576, Validation: 0.5669\n",
            "Epoch: 204, Loss: 1.5578, Validation: 0.5659\n",
            "Epoch: 205, Loss: 1.5572, Validation: 0.5672\n",
            "Epoch: 206, Loss: 1.5602, Validation: 0.5674\n",
            "Epoch: 207, Loss: 1.5521, Validation: 0.5668\n",
            "Epoch: 208, Loss: 1.5554, Validation: 0.5671\n",
            "Epoch: 209, Loss: 1.5571, Validation: 0.5680\n",
            "Epoch: 210, Loss: 1.5579, Validation: 0.5688\n",
            "Epoch: 211, Loss: 1.5591, Validation: 0.5685\n",
            "Epoch: 212, Loss: 1.5550, Validation: 0.5663\n",
            "Epoch: 213, Loss: 1.5556, Validation: 0.5655\n",
            "Epoch: 214, Loss: 1.5570, Validation: 0.5665\n",
            "Epoch: 215, Loss: 1.5591, Validation: 0.5677\n",
            "Epoch: 216, Loss: 1.5567, Validation: 0.5672\n",
            "Epoch: 217, Loss: 1.5507, Validation: 0.5677\n",
            "Epoch: 218, Loss: 1.5541, Validation: 0.5684\n",
            "Epoch: 219, Loss: 1.5552, Validation: 0.5699\n",
            "Epoch: 220, Loss: 1.5518, Validation: 0.5682\n",
            "Epoch: 221, Loss: 1.5541, Validation: 0.5694\n",
            "Epoch: 222, Loss: 1.5529, Validation: 0.5701\n",
            "Epoch: 223, Loss: 1.5529, Validation: 0.5699\n",
            "Epoch: 224, Loss: 1.5522, Validation: 0.5690\n",
            "Epoch: 225, Loss: 1.5548, Validation: 0.5679\n",
            "Epoch: 226, Loss: 1.5513, Validation: 0.5675\n",
            "Epoch: 227, Loss: 1.5529, Validation: 0.5673\n",
            "Epoch: 228, Loss: 1.5531, Validation: 0.5697\n",
            "Epoch: 229, Loss: 1.5546, Validation: 0.5682\n",
            "Epoch: 230, Loss: 1.5514, Validation: 0.5684\n",
            "Epoch: 231, Loss: 1.5495, Validation: 0.5688\n",
            "Epoch: 232, Loss: 1.5477, Validation: 0.5689\n",
            "Epoch: 233, Loss: 1.5520, Validation: 0.5698\n",
            "Epoch: 234, Loss: 1.5528, Validation: 0.5707\n",
            "Epoch: 235, Loss: 1.5495, Validation: 0.5718\n",
            "Epoch: 236, Loss: 1.5455, Validation: 0.5718\n",
            "Epoch: 237, Loss: 1.5544, Validation: 0.5712\n",
            "Epoch: 238, Loss: 1.5455, Validation: 0.5715\n",
            "Epoch: 239, Loss: 1.5487, Validation: 0.5709\n",
            "Epoch: 240, Loss: 1.5470, Validation: 0.5700\n",
            "Epoch: 241, Loss: 1.5508, Validation: 0.5704\n",
            "Epoch: 242, Loss: 1.5479, Validation: 0.5710\n",
            "Epoch: 243, Loss: 1.5484, Validation: 0.5704\n",
            "Epoch: 244, Loss: 1.5505, Validation: 0.5709\n",
            "Epoch: 245, Loss: 1.5485, Validation: 0.5704\n",
            "Epoch: 246, Loss: 1.5456, Validation: 0.5707\n",
            "Epoch: 247, Loss: 1.5444, Validation: 0.5723\n",
            "Epoch: 248, Loss: 1.5490, Validation: 0.5722\n",
            "Epoch: 249, Loss: 1.5461, Validation: 0.5718\n",
            "Epoch: 250, Loss: 1.5465, Validation: 0.5720\n",
            "Epoch: 251, Loss: 1.5516, Validation: 0.5716\n",
            "Epoch: 252, Loss: 1.5479, Validation: 0.5723\n",
            "Epoch: 253, Loss: 1.5504, Validation: 0.5717\n",
            "Epoch: 254, Loss: 1.5459, Validation: 0.5713\n",
            "Epoch: 255, Loss: 1.5454, Validation: 0.5699\n",
            "Epoch: 256, Loss: 1.5395, Validation: 0.5698\n",
            "Epoch: 257, Loss: 1.5457, Validation: 0.5700\n",
            "Epoch: 258, Loss: 1.5495, Validation: 0.5707\n",
            "Epoch: 259, Loss: 1.5428, Validation: 0.5691\n",
            "Epoch: 260, Loss: 1.5468, Validation: 0.5687\n",
            "Epoch: 261, Loss: 1.5455, Validation: 0.5700\n",
            "Epoch: 262, Loss: 1.5429, Validation: 0.5702\n",
            "Epoch: 263, Loss: 1.5445, Validation: 0.5699\n",
            "Epoch: 264, Loss: 1.5442, Validation: 0.5700\n",
            "Epoch: 265, Loss: 1.5445, Validation: 0.5695\n",
            "Epoch: 266, Loss: 1.5457, Validation: 0.5700\n",
            "Epoch: 267, Loss: 1.5417, Validation: 0.5732\n",
            "Epoch: 268, Loss: 1.5466, Validation: 0.5723\n",
            "Epoch: 269, Loss: 1.5439, Validation: 0.5715\n",
            "Epoch: 270, Loss: 1.5427, Validation: 0.5728\n",
            "Epoch: 271, Loss: 1.5433, Validation: 0.5721\n",
            "Epoch: 272, Loss: 1.5425, Validation: 0.5724\n",
            "Epoch: 273, Loss: 1.5379, Validation: 0.5721\n",
            "Epoch: 274, Loss: 1.5419, Validation: 0.5717\n",
            "Epoch: 275, Loss: 1.5414, Validation: 0.5714\n",
            "Epoch: 276, Loss: 1.5447, Validation: 0.5715\n",
            "Epoch: 277, Loss: 1.5422, Validation: 0.5716\n",
            "Epoch: 278, Loss: 1.5398, Validation: 0.5716\n",
            "Epoch: 279, Loss: 1.5427, Validation: 0.5706\n",
            "Epoch: 280, Loss: 1.5402, Validation: 0.5696\n",
            "Epoch: 281, Loss: 1.5398, Validation: 0.5683\n",
            "Epoch: 282, Loss: 1.5426, Validation: 0.5699\n",
            "Epoch: 283, Loss: 1.5406, Validation: 0.5702\n",
            "Epoch: 284, Loss: 1.5418, Validation: 0.5710\n",
            "Epoch: 285, Loss: 1.5419, Validation: 0.5725\n",
            "Epoch: 286, Loss: 1.5384, Validation: 0.5729\n",
            "Epoch: 287, Loss: 1.5381, Validation: 0.5733\n",
            "Epoch: 288, Loss: 1.5401, Validation: 0.5725\n",
            "Epoch: 289, Loss: 1.5373, Validation: 0.5714\n",
            "Epoch: 290, Loss: 1.5403, Validation: 0.5723\n",
            "Epoch: 291, Loss: 1.5417, Validation: 0.5717\n",
            "Epoch: 292, Loss: 1.5421, Validation: 0.5712\n",
            "Epoch: 293, Loss: 1.5411, Validation: 0.5702\n",
            "Epoch: 294, Loss: 1.5394, Validation: 0.5702\n",
            "Epoch: 295, Loss: 1.5357, Validation: 0.5701\n",
            "Epoch: 296, Loss: 1.5434, Validation: 0.5711\n",
            "Epoch: 297, Loss: 1.5399, Validation: 0.5716\n",
            "Epoch: 298, Loss: 1.5354, Validation: 0.5699\n",
            "Epoch: 299, Loss: 1.5360, Validation: 0.5691\n",
            "Epoch: 300, Loss: 1.5413, Validation: 0.5702\n",
            "Epoch: 301, Loss: 1.5385, Validation: 0.5691\n",
            "Epoch: 302, Loss: 1.5360, Validation: 0.5705\n",
            "Epoch: 303, Loss: 1.5417, Validation: 0.5697\n",
            "Epoch: 304, Loss: 1.5392, Validation: 0.5683\n",
            "Epoch: 305, Loss: 1.5409, Validation: 0.5701\n",
            "Epoch: 306, Loss: 1.5369, Validation: 0.5704\n",
            "Epoch: 307, Loss: 1.5337, Validation: 0.5718\n",
            "Epoch: 308, Loss: 1.5333, Validation: 0.5725\n",
            "Epoch: 309, Loss: 1.5406, Validation: 0.5724\n",
            "Epoch: 310, Loss: 1.5391, Validation: 0.5727\n",
            "Epoch: 311, Loss: 1.5349, Validation: 0.5737\n",
            "Epoch: 312, Loss: 1.5365, Validation: 0.5742\n",
            "Epoch: 313, Loss: 1.5328, Validation: 0.5736\n",
            "Epoch: 314, Loss: 1.5362, Validation: 0.5744\n",
            "Epoch: 315, Loss: 1.5366, Validation: 0.5744\n",
            "Epoch: 316, Loss: 1.5360, Validation: 0.5724\n",
            "Epoch: 317, Loss: 1.5410, Validation: 0.5717\n",
            "Epoch: 318, Loss: 1.5363, Validation: 0.5714\n",
            "Epoch: 319, Loss: 1.5380, Validation: 0.5739\n",
            "Epoch: 320, Loss: 1.5373, Validation: 0.5739\n",
            "Epoch: 321, Loss: 1.5381, Validation: 0.5736\n",
            "Epoch: 322, Loss: 1.5365, Validation: 0.5717\n",
            "Epoch: 323, Loss: 1.5299, Validation: 0.5713\n",
            "Epoch: 324, Loss: 1.5360, Validation: 0.5715\n",
            "Epoch: 325, Loss: 1.5311, Validation: 0.5736\n",
            "Epoch: 326, Loss: 1.5354, Validation: 0.5726\n",
            "Epoch: 327, Loss: 1.5351, Validation: 0.5707\n",
            "Epoch: 328, Loss: 1.5359, Validation: 0.5705\n",
            "Epoch: 329, Loss: 1.5345, Validation: 0.5710\n",
            "Epoch: 330, Loss: 1.5366, Validation: 0.5727\n",
            "Epoch: 331, Loss: 1.5346, Validation: 0.5720\n",
            "Epoch: 332, Loss: 1.5348, Validation: 0.5710\n",
            "Epoch: 333, Loss: 1.5338, Validation: 0.5691\n",
            "Epoch: 334, Loss: 1.5353, Validation: 0.5712\n",
            "Epoch: 335, Loss: 1.5340, Validation: 0.5726\n",
            "Epoch: 336, Loss: 1.5317, Validation: 0.5723\n",
            "Epoch: 337, Loss: 1.5347, Validation: 0.5733\n",
            "Epoch: 338, Loss: 1.5321, Validation: 0.5727\n",
            "Epoch: 339, Loss: 1.5325, Validation: 0.5724\n",
            "Epoch: 340, Loss: 1.5332, Validation: 0.5719\n",
            "Epoch: 341, Loss: 1.5257, Validation: 0.5722\n",
            "Epoch: 342, Loss: 1.5349, Validation: 0.5720\n",
            "Epoch: 343, Loss: 1.5314, Validation: 0.5721\n",
            "Epoch: 344, Loss: 1.5284, Validation: 0.5722\n",
            "Epoch: 345, Loss: 1.5343, Validation: 0.5725\n",
            "Epoch: 346, Loss: 1.5271, Validation: 0.5729\n",
            "Epoch: 347, Loss: 1.5322, Validation: 0.5738\n",
            "Epoch: 348, Loss: 1.5374, Validation: 0.5743\n",
            "Epoch: 349, Loss: 1.5351, Validation: 0.5736\n",
            "Epoch: 350, Loss: 1.5331, Validation: 0.5726\n",
            "Epoch: 351, Loss: 1.5296, Validation: 0.5711\n",
            "Epoch: 352, Loss: 1.5308, Validation: 0.5729\n",
            "Epoch: 353, Loss: 1.5299, Validation: 0.5726\n",
            "Epoch: 354, Loss: 1.5305, Validation: 0.5731\n",
            "Epoch: 355, Loss: 1.5355, Validation: 0.5726\n",
            "Epoch: 356, Loss: 1.5306, Validation: 0.5731\n",
            "Epoch: 357, Loss: 1.5298, Validation: 0.5738\n",
            "Epoch: 358, Loss: 1.5247, Validation: 0.5748\n",
            "Epoch: 359, Loss: 1.5277, Validation: 0.5740\n",
            "Epoch: 360, Loss: 1.5258, Validation: 0.5729\n",
            "Epoch: 361, Loss: 1.5288, Validation: 0.5723\n",
            "Epoch: 362, Loss: 1.5310, Validation: 0.5749\n",
            "Epoch: 363, Loss: 1.5317, Validation: 0.5741\n",
            "Epoch: 364, Loss: 1.5293, Validation: 0.5745\n",
            "Epoch: 365, Loss: 1.5310, Validation: 0.5744\n",
            "Epoch: 366, Loss: 1.5263, Validation: 0.5725\n",
            "Epoch: 367, Loss: 1.5272, Validation: 0.5725\n",
            "Epoch: 368, Loss: 1.5294, Validation: 0.5750\n",
            "Epoch: 369, Loss: 1.5275, Validation: 0.5768\n",
            "Epoch: 370, Loss: 1.5313, Validation: 0.5753\n",
            "Epoch: 371, Loss: 1.5308, Validation: 0.5750\n",
            "Epoch: 372, Loss: 1.5284, Validation: 0.5742\n",
            "Epoch: 373, Loss: 1.5287, Validation: 0.5746\n",
            "Epoch: 374, Loss: 1.5299, Validation: 0.5758\n",
            "Epoch: 375, Loss: 1.5255, Validation: 0.5764\n",
            "Epoch: 376, Loss: 1.5250, Validation: 0.5745\n",
            "Epoch: 377, Loss: 1.5265, Validation: 0.5746\n",
            "Epoch: 378, Loss: 1.5231, Validation: 0.5750\n",
            "Epoch: 379, Loss: 1.5303, Validation: 0.5749\n",
            "Epoch: 380, Loss: 1.5293, Validation: 0.5764\n",
            "Epoch: 381, Loss: 1.5260, Validation: 0.5752\n",
            "Epoch: 382, Loss: 1.5255, Validation: 0.5755\n",
            "Epoch: 383, Loss: 1.5340, Validation: 0.5765\n",
            "Epoch: 384, Loss: 1.5268, Validation: 0.5757\n",
            "Epoch: 385, Loss: 1.5309, Validation: 0.5754\n",
            "Epoch: 386, Loss: 1.5239, Validation: 0.5767\n",
            "Epoch: 387, Loss: 1.5275, Validation: 0.5751\n",
            "Epoch: 388, Loss: 1.5257, Validation: 0.5757\n",
            "Epoch: 389, Loss: 1.5280, Validation: 0.5766\n",
            "Epoch: 390, Loss: 1.5218, Validation: 0.5768\n",
            "Epoch: 391, Loss: 1.5204, Validation: 0.5756\n",
            "Epoch: 392, Loss: 1.5307, Validation: 0.5748\n",
            "Epoch: 393, Loss: 1.5253, Validation: 0.5733\n",
            "Epoch: 394, Loss: 1.5282, Validation: 0.5747\n",
            "Epoch: 395, Loss: 1.5280, Validation: 0.5746\n",
            "Epoch: 396, Loss: 1.5299, Validation: 0.5752\n",
            "Epoch: 397, Loss: 1.5293, Validation: 0.5744\n",
            "Epoch: 398, Loss: 1.5239, Validation: 0.5729\n",
            "Epoch: 399, Loss: 1.5237, Validation: 0.5726\n",
            "Epoch: 400, Loss: 1.5236, Validation: 0.5728\n",
            "Epoch: 401, Loss: 1.5226, Validation: 0.5728\n",
            "Epoch: 402, Loss: 1.5271, Validation: 0.5728\n",
            "Epoch: 403, Loss: 1.5237, Validation: 0.5708\n",
            "Epoch: 404, Loss: 1.5271, Validation: 0.5728\n",
            "Epoch: 405, Loss: 1.5255, Validation: 0.5750\n",
            "Epoch: 406, Loss: 1.5253, Validation: 0.5728\n",
            "Epoch: 407, Loss: 1.5237, Validation: 0.5708\n",
            "Epoch: 408, Loss: 1.5314, Validation: 0.5728\n",
            "Epoch: 409, Loss: 1.5279, Validation: 0.5759\n",
            "Epoch: 410, Loss: 1.5243, Validation: 0.5790\n",
            "Epoch: 411, Loss: 1.5268, Validation: 0.5764\n",
            "Epoch: 412, Loss: 1.5236, Validation: 0.5738\n",
            "Epoch: 413, Loss: 1.5214, Validation: 0.5749\n",
            "Epoch: 414, Loss: 1.5274, Validation: 0.5729\n",
            "Epoch: 415, Loss: 1.5291, Validation: 0.5725\n",
            "Epoch: 416, Loss: 1.5272, Validation: 0.5720\n",
            "Epoch: 417, Loss: 1.5256, Validation: 0.5718\n",
            "Epoch: 418, Loss: 1.5245, Validation: 0.5705\n",
            "Epoch: 419, Loss: 1.5247, Validation: 0.5727\n",
            "Epoch: 420, Loss: 1.5217, Validation: 0.5729\n",
            "Epoch: 421, Loss: 1.5211, Validation: 0.5742\n",
            "Epoch: 422, Loss: 1.5246, Validation: 0.5744\n",
            "Epoch: 423, Loss: 1.5257, Validation: 0.5738\n",
            "Epoch: 424, Loss: 1.5233, Validation: 0.5758\n",
            "Epoch: 425, Loss: 1.5223, Validation: 0.5726\n",
            "Epoch: 426, Loss: 1.5187, Validation: 0.5733\n",
            "Epoch: 427, Loss: 1.5207, Validation: 0.5756\n",
            "Epoch: 428, Loss: 1.5196, Validation: 0.5763\n",
            "Epoch: 429, Loss: 1.5227, Validation: 0.5748\n",
            "Epoch: 430, Loss: 1.5207, Validation: 0.5751\n",
            "Epoch: 431, Loss: 1.5259, Validation: 0.5764\n",
            "Epoch: 432, Loss: 1.5231, Validation: 0.5758\n",
            "Epoch: 433, Loss: 1.5229, Validation: 0.5756\n",
            "Epoch: 434, Loss: 1.5214, Validation: 0.5767\n",
            "Epoch: 435, Loss: 1.5234, Validation: 0.5758\n",
            "Epoch: 436, Loss: 1.5226, Validation: 0.5743\n",
            "Epoch: 437, Loss: 1.5227, Validation: 0.5750\n",
            "Epoch: 438, Loss: 1.5287, Validation: 0.5756\n",
            "Epoch: 439, Loss: 1.5245, Validation: 0.5762\n",
            "Epoch: 440, Loss: 1.5233, Validation: 0.5751\n",
            "Epoch: 441, Loss: 1.5197, Validation: 0.5758\n",
            "Epoch: 442, Loss: 1.5219, Validation: 0.5744\n",
            "Epoch: 443, Loss: 1.5201, Validation: 0.5762\n",
            "Epoch: 444, Loss: 1.5188, Validation: 0.5760\n",
            "Epoch: 445, Loss: 1.5182, Validation: 0.5778\n",
            "Epoch: 446, Loss: 1.5218, Validation: 0.5769\n",
            "Epoch: 447, Loss: 1.5179, Validation: 0.5771\n",
            "Epoch: 448, Loss: 1.5226, Validation: 0.5757\n",
            "Epoch: 449, Loss: 1.5164, Validation: 0.5759\n",
            "Epoch: 450, Loss: 1.5212, Validation: 0.5754\n",
            "Epoch: 451, Loss: 1.5220, Validation: 0.5766\n",
            "Epoch: 452, Loss: 1.5245, Validation: 0.5775\n",
            "Epoch: 453, Loss: 1.5224, Validation: 0.5767\n",
            "Epoch: 454, Loss: 1.5180, Validation: 0.5748\n",
            "Epoch: 455, Loss: 1.5244, Validation: 0.5762\n",
            "Epoch: 456, Loss: 1.5203, Validation: 0.5748\n",
            "Epoch: 457, Loss: 1.5212, Validation: 0.5761\n",
            "Epoch: 458, Loss: 1.5146, Validation: 0.5744\n",
            "Epoch: 459, Loss: 1.5244, Validation: 0.5738\n",
            "Epoch: 460, Loss: 1.5212, Validation: 0.5773\n",
            "Epoch: 461, Loss: 1.5170, Validation: 0.5770\n",
            "Epoch: 462, Loss: 1.5196, Validation: 0.5759\n",
            "Epoch: 463, Loss: 1.5169, Validation: 0.5755\n",
            "Epoch: 464, Loss: 1.5179, Validation: 0.5758\n",
            "Epoch: 465, Loss: 1.5187, Validation: 0.5744\n",
            "Epoch: 466, Loss: 1.5142, Validation: 0.5754\n",
            "Epoch: 467, Loss: 1.5188, Validation: 0.5756\n",
            "Epoch: 468, Loss: 1.5178, Validation: 0.5732\n",
            "Epoch: 469, Loss: 1.5209, Validation: 0.5755\n",
            "Epoch: 470, Loss: 1.5198, Validation: 0.5755\n",
            "Epoch: 471, Loss: 1.5156, Validation: 0.5741\n",
            "Epoch: 472, Loss: 1.5207, Validation: 0.5741\n",
            "Epoch: 473, Loss: 1.5203, Validation: 0.5742\n",
            "Epoch: 474, Loss: 1.5123, Validation: 0.5746\n",
            "Epoch: 475, Loss: 1.5171, Validation: 0.5761\n",
            "Epoch: 476, Loss: 1.5160, Validation: 0.5751\n",
            "Epoch: 477, Loss: 1.5200, Validation: 0.5759\n",
            "Epoch: 478, Loss: 1.5223, Validation: 0.5749\n",
            "Epoch: 479, Loss: 1.5219, Validation: 0.5752\n",
            "Epoch: 480, Loss: 1.5211, Validation: 0.5752\n",
            "Epoch: 481, Loss: 1.5203, Validation: 0.5760\n",
            "Epoch: 482, Loss: 1.5203, Validation: 0.5742\n",
            "Epoch: 483, Loss: 1.5147, Validation: 0.5758\n",
            "Epoch: 484, Loss: 1.5202, Validation: 0.5761\n",
            "Epoch: 485, Loss: 1.5186, Validation: 0.5775\n",
            "Epoch: 486, Loss: 1.5107, Validation: 0.5776\n",
            "Epoch: 487, Loss: 1.5157, Validation: 0.5773\n",
            "Epoch: 488, Loss: 1.5189, Validation: 0.5758\n",
            "Epoch: 489, Loss: 1.5222, Validation: 0.5757\n",
            "Epoch: 490, Loss: 1.5180, Validation: 0.5764\n",
            "Epoch: 491, Loss: 1.5155, Validation: 0.5763\n",
            "Epoch: 492, Loss: 1.5170, Validation: 0.5772\n",
            "Epoch: 493, Loss: 1.5128, Validation: 0.5773\n",
            "Epoch: 494, Loss: 1.5108, Validation: 0.5768\n",
            "Epoch: 495, Loss: 1.5181, Validation: 0.5766\n",
            "Epoch: 496, Loss: 1.5195, Validation: 0.5772\n",
            "Epoch: 497, Loss: 1.5151, Validation: 0.5790\n",
            "Epoch: 498, Loss: 1.5175, Validation: 0.5796\n",
            "Epoch: 499, Loss: 1.5159, Validation: 0.5804\n",
            "Epoch: 500, Loss: 1.5126, Validation: 0.5799\n",
            "0.5804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc = test(test_mask)\n",
        "test_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXDj0uKZUDcT",
        "outputId": "114d4864-dce6-4d53-8667-e0463ce7e4d0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5866"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}